{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c3d03d9",
   "metadata": {},
   "source": [
    "**Imports and set up**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa59d968",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from huggingface_hub import notebook_login\n",
    " \n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2549485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the device for GPU usage\n",
    "\n",
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48bc1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Login with the token to use mentalBERT\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a2ebbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('all-gendered.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b03c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new dataset with sentences and all symptom targets in one list\n",
    "train['list'] = train[train.columns[26:32]].values.tolist()\n",
    "new_train = train[['Sentence', 'list']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4b835b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"mental/mental-bert-base-uncased\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3a9faa",
   "metadata": {},
   "source": [
    "**Dataset and Dataloader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f915694e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters as used by the BDI-Sen authors\n",
    "MAX_LEN = 128\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "VALID_BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "LEARNING_RATE = 2e-05\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "torch.manual_seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989677cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#class to tokenize the data and create the dataset for the model\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.text = dataframe.Sentence\n",
    "        self.targets = dataframe.list\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.text[index])\n",
    "        text = \" \".join(text.split())\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa63a898",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the datasets\n",
    "\n",
    "training_set = CustomDataset(new_train, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebeea193",
   "metadata": {},
   "source": [
    "**Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c817082",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the customized model, by adding a drop out layer and a linear layer to get the final output for the model\n",
    "\n",
    "class MBERTClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MBERTClass, self).__init__()\n",
    "        self.l1 = AutoModel.from_pretrained(model_checkpoint)\n",
    "        self.l2 = torch.nn.Dropout(0.2)\n",
    "        self.l3 = torch.nn.Linear(768, 6)\n",
    "\n",
    "    def forward(self, ids, mask, token_type_ids):\n",
    "        _, output_1= self.l1(ids, attention_mask = mask, token_type_ids = token_type_ids, return_dict=False)\n",
    "        output_2 = self.l2(output_1)\n",
    "        output = self.l3(output_2)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e00c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(outputs, targets):\n",
    "    return torch.nn.BCEWithLogitsLoss()(outputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd5ef72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(epoch, loader):\n",
    "    model.train()\n",
    "    for _,data in enumerate(loader, 0):\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        mask = data['mask'].to(device, dtype = torch.long)\n",
    "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "        targets = data['targets'].to(device, dtype = torch.float)\n",
    "        outputs = model(ids, mask, token_type_ids)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(outputs, targets)        \n",
    "        \n",
    "        if _%5000==0:\n",
    "            print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666d8151",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "val_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "              }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d629f22e",
   "metadata": {},
   "source": [
    "**Cross-validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afb4b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=9 #allows for one depressed female in each val split\n",
    "splits=StratifiedGroupKFold(n_splits=k,shuffle=True,random_state=0)\n",
    "per_fold_result={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7f516e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stratification is based on depression/control and gender\n",
    "train['labelgen'] = train[train.columns[[1]+ [25]]].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b188c64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to create new labels\n",
    "def make_one_label(y):\n",
    "    y_new = LabelEncoder().fit_transform([''.join(str(l)) for l in y])\n",
    "    return y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671fc6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating new labels based on gender and depression (resulting in 4 labels)\n",
    "targets = np.array(train['labelgen'].values.tolist())\n",
    "y_labelgen = make_one_label(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016b3be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Subject'] = train['Subject'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95ca29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross validation\n",
    "\n",
    "history = {'models' : [], 'val' : [], 'valid_loss': [], 'valid_acc':[], 'valid_f1_micro':[], 'valid_f1_macro':[], 'valid_f1_weighted': []}\n",
    "\n",
    "for i, (train_idx,val_idx) in enumerate(splits.split(np.arange(len(training_set)), y_labelgen, train['Subject'])):\n",
    "    \n",
    "    print(\"Fold no.{}:\".format(i + 1))\n",
    "\n",
    "    train_data = Subset(training_set, train_idx)\n",
    "    val_data = Subset(training_set, val_idx)\n",
    "\n",
    "    train_loader = DataLoader(train_data, **train_params)\n",
    "    valid_loader = DataLoader(val_data, **val_params)\n",
    "    \n",
    "    model = MBERTClass()\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(params = model.parameters(), lr=LEARNING_RATE)\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        trainer(epoch, train_loader) \n",
    "    \n",
    "    history['models'].append(model.state_dict())\n",
    "    history['val'].append(val_idx)\n",
    "\n",
    "    model.eval()\n",
    "    fin_targets=[]\n",
    "    fin_outputs=[] \n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(valid_loader, 0):\n",
    "            ids = data['ids'].to(device, dtype = torch.long)\n",
    "            mask = data['mask'].to(device, dtype = torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "            targets = data['targets'].to(device, dtype = torch.float)\n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
    "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
    "    outputs, targets = fin_outputs, fin_targets\n",
    "    outputs = (np.array(outputs) >= 0.5).astype(int)\n",
    "    targets = [[int(num) for num in sublist] for sublist in targets]\n",
    "    accuracy = metrics.accuracy_score(targets, outputs)\n",
    "    print('Valid loss: ', loss, 'Valid accuracy: ', accuracy)\n",
    "    f1_score_micro = metrics.f1_score(targets, outputs, average='micro', zero_division = 0.0)\n",
    "    f1_score_macro = metrics.f1_score(targets, outputs, average='macro', zero_division = 0.0)\n",
    "    f1_score_weighted = metrics.f1_score(targets, outputs, average='weighted', zero_division = 0.0)\n",
    "    history['valid_loss'].append(loss)\n",
    "    history['valid_acc'].append(accuracy)\n",
    "    history['valid_f1_micro'].append(f1_score_micro)\n",
    "    history['valid_f1_macro'].append(f1_score_macro)\n",
    "    history['valid_f1_weighted'].append(f1_score_weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13d006d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the history file with the models, val_idx and performance measures\n",
    "\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except ImportError:  # Python 3.x\n",
    "    import pickle\n",
    "\n",
    "with open('9-CV-Category-history.p', 'wb') as fp:\n",
    "    pickle.dump(history, fp, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
