{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f22dbe7b",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0d818a4b-17fe-457c-9dac-3a4667ad07d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from huggingface_hub import login\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, multilabel_confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "from itertools import chain\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import math\n",
    "\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except ImportError:  # Python 3.x\n",
    "    import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f14e0ee5-f633-47ec-a0a4-5ed8face124b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the device for GPU usage\n",
    "\n",
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6ac44d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75be4e3",
   "metadata": {},
   "source": [
    "**Test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "131a0854",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "class CPU_Unpickler(pickle.Unpickler):\n",
    "    def find_class(self, module, name):\n",
    "        if module == 'torch.storage' and name == '_load_from_bytes':\n",
    "            return lambda b: torch.load(io.BytesIO(b), map_location='cpu')\n",
    "        else: return super().find_class(module, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "493d3f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the model files\n",
    "with open('9-CV-Category-history.p', 'rb') as fp:\n",
    "    history = CPU_Unpickler(fp).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "33d91ea2-e275-48d7-8450-e9b558650bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train files depends on model\n",
    "train = pd.read_csv('all-gendered.csv')\n",
    "#train = pd.read_csv('all_CV_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56009ce8-b689-4ef5-aa59-33c173b0ad45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1961d8d7",
   "metadata": {},
   "source": [
    "**Load models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2499b7e-2996-4c9c-a500-cc24b740971f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MBERTClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MBERTClass, self).__init__()\n",
    "        self.l1 = AutoModel.from_pretrained(\"mental/mental-bert-base-uncased\")\n",
    "        self.l2 = torch.nn.Dropout(0.2)\n",
    "        #self.l3 = torch.nn.Linear(768, 21)\n",
    "        self.l3 = torch.nn.Linear(768, 6)\n",
    "\n",
    "    def forward(self, ids, mask, token_type_ids):\n",
    "        _, output_1= self.l1(ids, attention_mask = mask, token_type_ids = token_type_ids, return_dict=False)\n",
    "        output_2 = self.l2(output_1)\n",
    "        output = self.l3(output_2)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e7d3ac",
   "metadata": {},
   "source": [
    "**Create testing sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e9e815f-c9d9-4fa7-811d-89f7acd6b1e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1c3ff435af0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_LEN = 128\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mental/mental-bert-base-uncased\")\n",
    "\n",
    "torch.manual_seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d49b5532-e25f-4fa6-90b1-94d05f788d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#class to tokenize the data and create the dataset for the model\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.text = dataframe.Sentence\n",
    "        self.targets = dataframe.list\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.text[index])\n",
    "        text = \" \".join(text.split())\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b04fa9f",
   "metadata": {},
   "source": [
    "**Evaluation and fairness measures**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c709638d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluation total\n",
    "\n",
    "def eval_total(model, test_loader):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    fin_targets=[]\n",
    "    fin_outputs=[]\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(test_loader, 0):\n",
    "            ids = data['ids'].to(device, dtype = torch.long)\n",
    "            mask = data['mask'].to(device, dtype = torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "            targets = data['targets'].to(device, dtype = torch.float)\n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
    "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
    "    outputs, targets = fin_outputs, fin_targets\n",
    "    outputs = (np.array(outputs) >= 0.5).astype(int)\n",
    "    targets = [[int(num) for num in sublist] for sublist in targets]\n",
    "    accuracy = metrics.accuracy_score(targets, outputs)\n",
    "    f1_score_micro = metrics.f1_score(targets, outputs, average='micro', zero_division = 0.0)\n",
    "    f1_score_macro = metrics.f1_score(targets, outputs, average='macro', zero_division = 0.0)\n",
    "    f1_score_weighted = metrics.f1_score(targets, outputs, average='weighted', zero_division = 0.0)\n",
    "    print(f\"Accuracy Score = {accuracy}\")\n",
    "    print(f\"F1 Score (Micro) = {f1_score_micro}\")\n",
    "    print(f\"F1 Score (Macro) = {f1_score_macro}\")\n",
    "    print(f\"F1 Score (Weighted) = {f1_score_weighted}\")\n",
    "\n",
    "    #precision_micro = precision_score(targets, outputs, average='micro', zero_division = 0.0)\n",
    "    precision_macro = precision_score(targets, outputs, average='macro', zero_division = 0.0)\n",
    "    #recall_micro = recall_score(targets, outputs, average='micro', zero_division = 0.0)\n",
    "    recall_macro = recall_score(targets, outputs, average='macro', zero_division = 0.0)\n",
    "    \n",
    "    #print(f\"Precision (Micro) = {precision_micro}\")\n",
    "    print(f\"Precision (Macro) = {precision_macro}\")\n",
    "    #print(f\"Recall (Micro) = {recall_micro}\")\n",
    "    print(f\"Recall (Macro) = {recall_macro}\")    \n",
    "    \n",
    "    #auc_micro = roc_auc_score(targets, outputs, average='micro')\n",
    "    #print(f\"AUC = {auc_micro}\")\n",
    "    return targets, outputs, accuracy, f1_score_micro, f1_score_macro, f1_score_weighted, precision_macro, recall_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "082e62c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Categories model F1 Score per category\n",
    "\n",
    "def category_performance(targets, outputs):\n",
    "\n",
    "    all_accuracy = []\n",
    "    all_f1_score = []\n",
    "    #print(targets[0])\n",
    "    try:\n",
    "        print(targets[0])\n",
    "    except:\n",
    "        print('No Targets')\n",
    "        return\n",
    "    for i in range(len(targets[0])):\n",
    "            category_targets = [category[i] for category in targets]\n",
    "            category_outputs = [category[i] for category in outputs]\n",
    "            accuracy = metrics.accuracy_score(category_targets, category_outputs)\n",
    "            f1_score = metrics.f1_score(category_targets, category_outputs, zero_division = 0.0)\n",
    "            print('\\nCategory: ', testdata.columns[i+26])\n",
    "            print(f\"Accuracy Score = {accuracy}\")\n",
    "            print(f\"F1 Score = {f1_score}\")\n",
    "            all_accuracy.append(accuracy)\n",
    "            all_f1_score.append(f1_score)\n",
    "    return all_accuracy, all_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "024af3d1-bdb8-4c88-af4c-bf953da6c896",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that returns the TPR and FPR rate, as well as the number of positive targets\n",
    "def TPR_FPR(targets, outputs):\n",
    "    TP = 0\n",
    "    FN = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "\n",
    "    a = 1\n",
    "\n",
    "    for i in range(len(outputs)):\n",
    "        if outputs[i]==targets[i]==1:\n",
    "          TP +=1  \n",
    "        if outputs[i]==0 and targets[i]==1:\n",
    "          FN +=1\n",
    "        if outputs[i]==1 and targets[i]==0:\n",
    "           FP +=1\n",
    "        if outputs[i]==targets[i]==0:\n",
    "           TN +=1\n",
    "    \n",
    "    TP_rate = (TP+a)/(FN+TP+a)\n",
    "    FP_rate = (FP+a)/(FP+TN+a)\n",
    "    P = TP + FN\n",
    "    \n",
    "    return TP_rate, FP_rate, P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d43c4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#category model equal opportunity and equalized odds\n",
    "def category_equal_odds(male_targets, female_targets, male_outputs, female_outputs):\n",
    "\n",
    "    #s=0.0001\n",
    "    #equal_odds_all = []\n",
    "    P_all = []\n",
    "    m_P_all = []\n",
    "    f_P_all = []\n",
    "    all_m_TP = []\n",
    "    all_m_FP = []\n",
    "    all_f_TP = []\n",
    "    all_f_FP = []\n",
    "    all_equal_opp = []\n",
    "    all_fp_diff = []\n",
    "\n",
    "    try:\n",
    "        print(male_targets[0])\n",
    "    except:\n",
    "        print('No Targets')\n",
    "        return\n",
    "    for i in range(len(male_targets[0])):\n",
    "            print('Category: ', testdata.columns[i+26])\n",
    "            male_category_targets = [category[i] for category in male_targets]\n",
    "            female_category_targets = [category[i] for category in female_targets]\n",
    "            male_category_outputs = [category[i] for category in male_outputs]\n",
    "            female_category_outputs = [category[i] for category in female_outputs]\n",
    "    \n",
    "            male_TP_rate, male_FP_rate, male_P = TPR_FPR(male_category_targets, male_category_outputs)\n",
    "            female_TP_rate, female_FP_rate, female_P = TPR_FPR(female_category_targets, female_category_outputs)\n",
    "            P_category = male_P + female_P\n",
    "            P_all.append(P_category)\n",
    "            m_P_all.append(male_P)\n",
    "            f_P_all.append(female_P)\n",
    "            equal_opp = male_TP_rate/female_TP_rate\n",
    "            FP_diff = male_FP_rate/female_FP_rate\n",
    "            #equal_odds = max(equal_opp, FP_diff)\n",
    "            #equal_odds_all.append(equal_odds)\n",
    "            print('Equal opportunity: ', equal_opp)\n",
    "            print('FPR Difference: ', FP_diff)\n",
    "            all_equal_opp.append(equal_opp)\n",
    "            all_fp_diff.append(FP_diff)\n",
    "            all_m_TP.append(male_TP_rate)\n",
    "            all_m_FP.append(male_FP_rate)\n",
    "            all_f_TP.append(female_TP_rate)\n",
    "            all_f_FP.append(female_FP_rate)\n",
    "    return all_equal_opp, all_fp_diff, all_m_TP, all_m_FP, all_f_TP, all_f_FP, P_all, m_P_all, f_P_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b893a61a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at mental/mental-bert-base-uncased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 0.4605809128630705\n",
      "F1 Score (Micro) = 0.6095238095238096\n",
      "F1 Score (Macro) = 0.448161318521527\n",
      "F1 Score (Weighted) = 0.6043637490852081\n",
      "Precision (Macro) = 0.4932332988598973\n",
      "Recall (Macro) = 0.42898255398255386\n",
      "Accuracy Score = 0.8360655737704918\n",
      "F1 Score (Micro) = 0.6470588235294118\n",
      "F1 Score (Macro) = 0.3333333333333333\n",
      "F1 Score (Weighted) = 0.6296296296296295\n",
      "Precision (Macro) = 0.34722222222222215\n",
      "Recall (Macro) = 0.3222222222222222\n",
      "Accuracy Score = 0.3333333333333333\n",
      "F1 Score (Micro) = 0.6069246435845214\n",
      "F1 Score (Macro) = 0.44654291519045614\n",
      "F1 Score (Weighted) = 0.6022118270061299\n",
      "Precision (Macro) = 0.495436875038114\n",
      "Recall (Macro) = 0.42631613175950306\n",
      "[1, 0, 0, 1, 0, 0]\n",
      "\n",
      "Category:  Affective\n",
      "Accuracy Score = 0.7178423236514523\n",
      "F1 Score = 0.7017543859649122\n",
      "\n",
      "Category:  Motivational\n",
      "Accuracy Score = 0.8464730290456431\n",
      "F1 Score = 0.5842696629213483\n",
      "\n",
      "Category:  Cognitive\n",
      "Accuracy Score = 0.9253112033195021\n",
      "F1 Score = 0.3076923076923077\n",
      "\n",
      "Category:  Cog_distortions\n",
      "Accuracy Score = 0.8091286307053942\n",
      "F1 Score = 0.603448275862069\n",
      "\n",
      "Category:  Behavioral\n",
      "Accuracy Score = 0.8713692946058091\n",
      "F1 Score = 0.4918032786885246\n",
      "\n",
      "Category:  Physiological\n",
      "Accuracy Score = 0.979253112033195\n",
      "F1 Score = 0.0\n",
      "[1, 0, 0, 0, 0, 0]\n",
      "\n",
      "Category:  Affective\n",
      "Accuracy Score = 0.9016393442622951\n",
      "F1 Score = 0.6666666666666666\n",
      "\n",
      "Category:  Motivational\n",
      "Accuracy Score = 0.9508196721311475\n",
      "F1 Score = 0.6666666666666666\n",
      "\n",
      "Category:  Cognitive\n",
      "Accuracy Score = 1.0\n",
      "F1 Score = 0.0\n",
      "\n",
      "Category:  Cog_distortions\n",
      "Accuracy Score = 0.9672131147540983\n",
      "F1 Score = 0.6666666666666666\n",
      "\n",
      "Category:  Behavioral\n",
      "Accuracy Score = 1.0\n",
      "F1 Score = 0.0\n",
      "\n",
      "Category:  Physiological\n",
      "Accuracy Score = 0.9836065573770492\n",
      "F1 Score = 0.0\n",
      "[1, 0, 0, 1, 0, 0]\n",
      "\n",
      "Category:  Affective\n",
      "Accuracy Score = 0.6555555555555556\n",
      "F1 Score = 0.7047619047619048\n",
      "\n",
      "Category:  Motivational\n",
      "Accuracy Score = 0.8111111111111111\n",
      "F1 Score = 0.575\n",
      "\n",
      "Category:  Cognitive\n",
      "Accuracy Score = 0.9\n",
      "F1 Score = 0.3076923076923077\n",
      "\n",
      "Category:  Cog_distortions\n",
      "Accuracy Score = 0.7555555555555555\n",
      "F1 Score = 0.6\n",
      "\n",
      "Category:  Behavioral\n",
      "Accuracy Score = 0.8277777777777777\n",
      "F1 Score = 0.4918032786885246\n",
      "\n",
      "Category:  Physiological\n",
      "Accuracy Score = 0.9777777777777777\n",
      "F1 Score = 0.0\n",
      "[1, 0, 0, 0, 0, 0]\n",
      "Category:  Affective\n",
      "Equal opportunity:  0.9613333333333333\n",
      "FPR Difference:  0.17035040431266846\n",
      "Category:  Motivational\n",
      "Equal opportunity:  1.4444444444444442\n",
      "FPR Difference:  0.6516290726817042\n",
      "Category:  Cognitive\n",
      "Equal opportunity:  2.5999999999999996\n",
      "FPR Difference:  0.24780058651026393\n",
      "Category:  Cog_distortions\n",
      "Equal opportunity:  1.5\n",
      "FPR Difference:  0.35130970724191063\n",
      "Category:  Behavioral\n",
      "Equal opportunity:  1.75\n",
      "FPR Difference:  0.12419354838709679\n",
      "Category:  Physiological\n",
      "Equal opportunity:  2.5\n",
      "FPR Difference:  2.9016393442622954\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at mental/mental-bert-base-uncased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 0.835820895522388\n",
      "F1 Score (Micro) = 0.3783783783783784\n",
      "F1 Score (Macro) = 0.18055555555555555\n",
      "F1 Score (Weighted) = 0.38636363636363635\n",
      "Precision (Macro) = 0.1323529411764706\n",
      "Recall (Macro) = 0.28571428571428575\n",
      "Accuracy Score = 0.8524590163934426\n",
      "F1 Score (Micro) = 0.5833333333333334\n",
      "F1 Score (Macro) = 0.23137254901960783\n",
      "F1 Score (Weighted) = 0.5197860962566846\n",
      "Precision (Macro) = 0.19444444444444442\n",
      "Recall (Macro) = 0.28571428571428575\n",
      "Accuracy Score = 0.821917808219178\n",
      "F1 Score (Micro) = 0.0\n",
      "F1 Score (Macro) = 0.0\n",
      "F1 Score (Weighted) = 0.0\n",
      "Precision (Macro) = 0.0\n",
      "Recall (Macro) = 0.0\n",
      "[1, 0, 0, 0, 0, 0]\n",
      "\n",
      "Category:  Affective\n",
      "Accuracy Score = 0.8955223880597015\n",
      "F1 Score = 0.4166666666666667\n",
      "\n",
      "Category:  Motivational\n",
      "Accuracy Score = 0.9626865671641791\n",
      "F1 Score = 0.0\n",
      "\n",
      "Category:  Cognitive\n",
      "Accuracy Score = 1.0\n",
      "F1 Score = 0.0\n",
      "\n",
      "Category:  Cog_distortions\n",
      "Accuracy Score = 0.9925373134328358\n",
      "F1 Score = 0.0\n",
      "\n",
      "Category:  Behavioral\n",
      "Accuracy Score = 0.9850746268656716\n",
      "F1 Score = 0.6666666666666666\n",
      "\n",
      "Category:  Physiological\n",
      "Accuracy Score = 0.9925373134328358\n",
      "F1 Score = 0.0\n",
      "[1, 0, 0, 0, 0, 0]\n",
      "\n",
      "Category:  Affective\n",
      "Accuracy Score = 0.8852459016393442\n",
      "F1 Score = 0.5882352941176471\n",
      "\n",
      "Category:  Motivational\n",
      "Accuracy Score = 0.9836065573770492\n",
      "F1 Score = 0.0\n",
      "\n",
      "Category:  Cognitive\n",
      "Accuracy Score = 1.0\n",
      "F1 Score = 0.0\n",
      "\n",
      "Category:  Cog_distortions\n",
      "Accuracy Score = 0.9836065573770492\n",
      "F1 Score = 0.0\n",
      "\n",
      "Category:  Behavioral\n",
      "Accuracy Score = 0.9836065573770492\n",
      "F1 Score = 0.8\n",
      "\n",
      "Category:  Physiological\n",
      "Accuracy Score = 1.0\n",
      "F1 Score = 0.0\n",
      "[0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Category:  Affective\n",
      "Accuracy Score = 0.9041095890410958\n",
      "F1 Score = 0.0\n",
      "\n",
      "Category:  Motivational\n",
      "Accuracy Score = 0.9452054794520548\n",
      "F1 Score = 0.0\n",
      "\n",
      "Category:  Cognitive\n",
      "Accuracy Score = 1.0\n",
      "F1 Score = 0.0\n",
      "\n",
      "Category:  Cog_distortions\n",
      "Accuracy Score = 1.0\n",
      "F1 Score = 0.0\n",
      "\n",
      "Category:  Behavioral\n",
      "Accuracy Score = 0.9863013698630136\n",
      "F1 Score = 0.0\n",
      "\n",
      "Category:  Physiological\n",
      "Accuracy Score = 0.9863013698630136\n",
      "F1 Score = 0.0\n",
      "[1, 0, 0, 0, 0, 0]\n",
      "Category:  Affective\n",
      "Equal opportunity:  0.75\n",
      "FPR Difference:  1.009090909090909\n",
      "Category:  Motivational\n",
      "Equal opportunity:  0.5\n",
      "FPR Difference:  0.24262295081967214\n",
      "Category:  Cognitive\n",
      "Equal opportunity:  1.0\n",
      "FPR Difference:  1.193548387096774\n",
      "Category:  Cog_distortions\n",
      "Equal opportunity:  0.5\n",
      "FPR Difference:  1.2131147540983607\n",
      "Category:  Behavioral\n",
      "Equal opportunity:  1.0\n",
      "FPR Difference:  1.2333333333333332\n",
      "Category:  Physiological\n",
      "Equal opportunity:  1.0\n",
      "FPR Difference:  0.596774193548387\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at mental/mental-bert-base-uncased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 0.8194444444444444\n",
      "F1 Score (Micro) = 0.6923076923076923\n",
      "F1 Score (Macro) = 0.5944444444444444\n",
      "F1 Score (Weighted) = 0.6935897435897436\n",
      "Precision (Macro) = 0.6722222222222222\n",
      "Recall (Macro) = 0.5727513227513227\n",
      "Accuracy Score = 0.9347826086956522\n",
      "F1 Score (Micro) = 0.0\n",
      "F1 Score (Macro) = 0.0\n",
      "F1 Score (Weighted) = 0.0\n",
      "Precision (Macro) = 0.0\n",
      "Recall (Macro) = 0.0\n",
      "Accuracy Score = 0.6153846153846154\n",
      "F1 Score (Micro) = 0.7346938775510204\n",
      "F1 Score (Macro) = 0.6103174603174603\n",
      "F1 Score (Weighted) = 0.7265567765567766\n",
      "Precision (Macro) = 0.6944444444444443\n",
      "Recall (Macro) = 0.5727513227513227\n",
      "[0, 1, 0, 0, 0, 0]\n",
      "\n",
      "Category:  Affective\n",
      "Accuracy Score = 0.8888888888888888\n",
      "F1 Score = 0.6666666666666666\n",
      "\n",
      "Category:  Motivational\n",
      "Accuracy Score = 0.9583333333333334\n",
      "F1 Score = 0.6666666666666666\n",
      "\n",
      "Category:  Cognitive\n",
      "Accuracy Score = 1.0\n",
      "F1 Score = 0.0\n",
      "\n",
      "Category:  Cog_distortions\n",
      "Accuracy Score = 0.9583333333333334\n",
      "F1 Score = 0.4\n",
      "\n",
      "Category:  Behavioral\n",
      "Accuracy Score = 0.9722222222222222\n",
      "F1 Score = 0.8333333333333334\n",
      "\n",
      "Category:  Physiological\n",
      "Accuracy Score = 1.0\n",
      "F1 Score = 1.0\n",
      "[0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Category:  Affective\n",
      "Accuracy Score = 0.9347826086956522\n",
      "F1 Score = 0.0\n",
      "\n",
      "Category:  Motivational\n",
      "Accuracy Score = 1.0\n",
      "F1 Score = 0.0\n",
      "\n",
      "Category:  Cognitive\n",
      "Accuracy Score = 1.0\n",
      "F1 Score = 0.0\n",
      "\n",
      "Category:  Cog_distortions\n",
      "Accuracy Score = 1.0\n",
      "F1 Score = 0.0\n",
      "\n",
      "Category:  Behavioral\n",
      "Accuracy Score = 1.0\n",
      "F1 Score = 0.0\n",
      "\n",
      "Category:  Physiological\n",
      "Accuracy Score = 1.0\n",
      "F1 Score = 0.0\n",
      "[0, 1, 0, 0, 0, 0]\n",
      "\n",
      "Category:  Affective\n",
      "Accuracy Score = 0.8076923076923077\n",
      "F1 Score = 0.7619047619047619\n",
      "\n",
      "Category:  Motivational\n",
      "Accuracy Score = 0.8846153846153846\n",
      "F1 Score = 0.6666666666666666\n",
      "\n",
      "Category:  Cognitive\n",
      "Accuracy Score = 1.0\n",
      "F1 Score = 0.0\n",
      "\n",
      "Category:  Cog_distortions\n",
      "Accuracy Score = 0.8846153846153846\n",
      "F1 Score = 0.4\n",
      "\n",
      "Category:  Behavioral\n",
      "Accuracy Score = 0.9230769230769231\n",
      "F1 Score = 0.8333333333333334\n",
      "\n",
      "Category:  Physiological\n",
      "Accuracy Score = 1.0\n",
      "F1 Score = 1.0\n",
      "[0, 0, 0, 0, 0, 0]\n",
      "Category:  Affective\n",
      "Equal opportunity:  1.1111111111111112\n",
      "FPR Difference:  0.30638297872340425\n",
      "Category:  Motivational\n",
      "Equal opportunity:  1.75\n",
      "FPR Difference:  0.4468085106382979\n",
      "Category:  Cognitive\n",
      "Equal opportunity:  1.0\n",
      "FPR Difference:  0.574468085106383\n",
      "Category:  Cog_distortions\n",
      "Equal opportunity:  2.0\n",
      "FPR Difference:  0.25531914893617025\n",
      "Category:  Behavioral\n",
      "Equal opportunity:  1.3333333333333333\n",
      "FPR Difference:  0.42553191489361697\n",
      "Category:  Physiological\n",
      "Equal opportunity:  1.0\n",
      "FPR Difference:  0.553191489361702\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at mental/mental-bert-base-uncased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 0.8604651162790697\n",
      "F1 Score (Micro) = 0.6129032258064516\n",
      "F1 Score (Macro) = 0.4348583877995642\n",
      "F1 Score (Weighted) = 0.5857895846510647\n",
      "Precision (Macro) = 0.4473684210526316\n",
      "Recall (Macro) = 0.48095238095238096\n",
      "Accuracy Score = 0.3684210526315789\n",
      "F1 Score (Micro) = 0.6785714285714286\n",
      "F1 Score (Macro) = 0.47301587301587295\n",
      "F1 Score (Weighted) = 0.6556067588325654\n",
      "Precision (Macro) = 0.561111111111111\n",
      "Recall (Macro) = 0.48095238095238096\n",
      "Accuracy Score = 0.9454545454545454\n",
      "F1 Score (Micro) = 0.0\n",
      "F1 Score (Macro) = 0.0\n",
      "F1 Score (Weighted) = 0.0\n",
      "Precision (Macro) = 0.0\n",
      "Recall (Macro) = 0.0\n",
      "[1, 1, 1, 0, 0, 0]\n",
      "\n",
      "Category:  Affective\n",
      "Accuracy Score = 0.937984496124031\n",
      "F1 Score = 0.7647058823529411\n",
      "\n",
      "Category:  Motivational\n",
      "Accuracy Score = 0.9534883720930233\n",
      "F1 Score = 0.4\n",
      "\n",
      "Category:  Cognitive\n",
      "Accuracy Score = 0.9689922480620154\n",
      "F1 Score = 0.3333333333333333\n",
      "\n",
      "Category:  Cog_distortions\n",
      "Accuracy Score = 0.9612403100775194\n",
      "F1 Score = 0.4444444444444444\n",
      "\n",
      "Category:  Behavioral\n",
      "Accuracy Score = 0.9922480620155039\n",
      "F1 Score = 0.6666666666666666\n",
      "\n",
      "Category:  Physiological\n",
      "Accuracy Score = 1.0\n",
      "F1 Score = 0.0\n",
      "[1, 1, 1, 0, 0, 0]\n",
      "\n",
      "Category:  Affective\n",
      "Accuracy Score = 0.7894736842105263\n",
      "F1 Score = 0.8666666666666667\n",
      "\n",
      "Category:  Motivational\n",
      "Accuracy Score = 0.6842105263157895\n",
      "F1 Score = 0.4\n",
      "\n",
      "Category:  Cognitive\n",
      "Accuracy Score = 0.7894736842105263\n",
      "F1 Score = 0.3333333333333333\n",
      "\n",
      "Category:  Cog_distortions\n",
      "Accuracy Score = 0.8421052631578947\n",
      "F1 Score = 0.5714285714285714\n",
      "\n",
      "Category:  Behavioral\n",
      "Accuracy Score = 0.9473684210526315\n",
      "F1 Score = 0.6666666666666666\n",
      "\n",
      "Category:  Physiological\n",
      "Accuracy Score = 1.0\n",
      "F1 Score = 0.0\n",
      "[0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Category:  Affective\n",
      "Accuracy Score = 0.9636363636363636\n",
      "F1 Score = 0.0\n",
      "\n",
      "Category:  Motivational\n",
      "Accuracy Score = 1.0\n",
      "F1 Score = 0.0\n",
      "\n",
      "Category:  Cognitive\n",
      "Accuracy Score = 1.0\n",
      "F1 Score = 0.0\n",
      "\n",
      "Category:  Cog_distortions\n",
      "Accuracy Score = 0.9818181818181818\n",
      "F1 Score = 0.0\n",
      "\n",
      "Category:  Behavioral\n",
      "Accuracy Score = 1.0\n",
      "F1 Score = 0.0\n",
      "\n",
      "Category:  Physiological\n",
      "Accuracy Score = 1.0\n",
      "F1 Score = 0.0\n",
      "[1, 1, 1, 0, 0, 0]\n",
      "Category:  Affective\n",
      "Equal opportunity:  0.875\n",
      "FPR Difference:  13.32\n",
      "Category:  Motivational\n",
      "Equal opportunity:  0.375\n",
      "FPR Difference:  17.076923076923077\n",
      "Category:  Cognitive\n",
      "Equal opportunity:  0.5\n",
      "FPR Difference:  19.58823529411765\n",
      "Category:  Cog_distortions\n",
      "Equal opportunity:  0.5\n",
      "FPR Difference:  2.4666666666666663\n",
      "Category:  Behavioral\n",
      "Equal opportunity:  1.0\n",
      "FPR Difference:  11.68421052631579\n",
      "Category:  Physiological\n",
      "Equal opportunity:  1.0\n",
      "FPR Difference:  5.550000000000001\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at mental/mental-bert-base-uncased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 0.5529411764705883\n",
      "F1 Score (Micro) = 0.5862068965517241\n",
      "F1 Score (Macro) = 0.3842072157122618\n",
      "F1 Score (Weighted) = 0.5641176914068996\n",
      "Precision (Macro) = 0.4296743571256909\n",
      "Recall (Macro) = 0.3636166832324328\n",
      "Accuracy Score = 0.42424242424242425\n",
      "F1 Score (Micro) = 0.5675675675675675\n",
      "F1 Score (Macro) = 0.35714285714285715\n",
      "F1 Score (Weighted) = 0.5034632034632035\n",
      "Precision (Macro) = 0.4557017543859649\n",
      "Recall (Macro) = 0.3229166666666667\n",
      "Accuracy Score = 0.583941605839416\n",
      "F1 Score (Micro) = 0.5925925925925926\n",
      "F1 Score (Macro) = 0.3914562443486997\n",
      "F1 Score (Weighted) = 0.5834538473245097\n",
      "Precision (Macro) = 0.4134944213375586\n",
      "Recall (Macro) = 0.3864219114219114\n",
      "[0, 0, 0, 1, 0, 0]\n",
      "\n",
      "Category:  Affective\n",
      "Accuracy Score = 0.7941176470588235\n",
      "F1 Score = 0.7286821705426356\n",
      "\n",
      "Category:  Motivational\n",
      "Accuracy Score = 0.8529411764705882\n",
      "F1 Score = 0.5454545454545454\n",
      "\n",
      "Category:  Cognitive\n",
      "Accuracy Score = 0.9352941176470588\n",
      "F1 Score = 0.0\n",
      "\n",
      "Category:  Cog_distortions\n",
      "Accuracy Score = 0.9\n",
      "F1 Score = 0.5405405405405406\n",
      "\n",
      "Category:  Behavioral\n",
      "Accuracy Score = 0.8411764705882353\n",
      "F1 Score = 0.49056603773584906\n",
      "\n",
      "Category:  Physiological\n",
      "Accuracy Score = 0.9705882352941176\n",
      "F1 Score = 0.0\n",
      "[0, 0, 0, 1, 0, 0]\n",
      "\n",
      "Category:  Affective\n",
      "Accuracy Score = 0.7272727272727273\n",
      "F1 Score = 0.7428571428571429\n",
      "\n",
      "Category:  Motivational\n",
      "Accuracy Score = 0.9090909090909091\n",
      "F1 Score = 0.6666666666666666\n",
      "\n",
      "Category:  Cognitive\n",
      "Accuracy Score = 0.8484848484848485\n",
      "F1 Score = 0.0\n",
      "\n",
      "Category:  Cog_distortions\n",
      "Accuracy Score = 0.7878787878787878\n",
      "F1 Score = 0.5333333333333333\n",
      "\n",
      "Category:  Behavioral\n",
      "Accuracy Score = 0.7575757575757576\n",
      "F1 Score = 0.2\n",
      "\n",
      "Category:  Physiological\n",
      "Accuracy Score = 1.0\n",
      "F1 Score = 0.0\n",
      "[1, 0, 0, 1, 0, 0]\n",
      "\n",
      "Category:  Affective\n",
      "Accuracy Score = 0.8102189781021898\n",
      "F1 Score = 0.723404255319149\n",
      "\n",
      "Category:  Motivational\n",
      "Accuracy Score = 0.8394160583941606\n",
      "F1 Score = 0.5217391304347826\n",
      "\n",
      "Category:  Cognitive\n",
      "Accuracy Score = 0.9562043795620438\n",
      "F1 Score = 0.0\n",
      "\n",
      "Category:  Cog_distortions\n",
      "Accuracy Score = 0.927007299270073\n",
      "F1 Score = 0.5454545454545454\n",
      "\n",
      "Category:  Behavioral\n",
      "Accuracy Score = 0.8613138686131386\n",
      "F1 Score = 0.5581395348837209\n",
      "\n",
      "Category:  Physiological\n",
      "Accuracy Score = 0.9635036496350365\n",
      "F1 Score = 0.0\n",
      "[0, 0, 0, 1, 0, 0]\n",
      "Category:  Affective\n",
      "Equal opportunity:  0.9647058823529412\n",
      "FPR Difference:  1.8148148148148149\n",
      "Category:  Motivational\n",
      "Equal opportunity:  1.3846153846153846\n",
      "FPR Difference:  0.8582375478927202\n",
      "Category:  Cognitive\n",
      "Equal opportunity:  0.3333333333333333\n",
      "FPR Difference:  0.7873563218390804\n",
      "Category:  Cog_distortions\n",
      "Equal opportunity:  0.7792207792207791\n",
      "FPR Difference:  1.7638888888888888\n",
      "Category:  Behavioral\n",
      "Equal opportunity:  0.46153846153846156\n",
      "FPR Difference:  1.4358974358974361\n",
      "Category:  Physiological\n",
      "Equal opportunity:  5.0\n",
      "FPR Difference:  1.9705882352941178\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at mental/mental-bert-base-uncased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 0.8070175438596491\n",
      "F1 Score (Micro) = 0.7169811320754716\n",
      "F1 Score (Macro) = 0.5435045574580458\n",
      "F1 Score (Weighted) = 0.6875877610761332\n",
      "Precision (Macro) = 0.6468253968253969\n",
      "Recall (Macro) = 0.5537878787878788\n",
      "Accuracy Score = 0.4864864864864865\n",
      "F1 Score (Micro) = 0.7272727272727273\n",
      "F1 Score (Macro) = 0.5539682539682539\n",
      "F1 Score (Weighted) = 0.6957771787960468\n",
      "Precision (Macro) = 0.6676406926406927\n",
      "Recall (Macro) = 0.5482323232323232\n",
      "Accuracy Score = 0.961038961038961\n",
      "F1 Score (Micro) = 0.5714285714285714\n",
      "F1 Score (Macro) = 0.13333333333333333\n",
      "F1 Score (Weighted) = 0.8\n",
      "Precision (Macro) = 0.1111111111111111\n",
      "Recall (Macro) = 0.16666666666666666\n",
      "[1, 1, 1, 1, 1, 0]\n",
      "\n",
      "Category:  Affective\n",
      "Accuracy Score = 0.9210526315789473\n",
      "F1 Score = 0.7906976744186046\n",
      "\n",
      "Category:  Motivational\n",
      "Accuracy Score = 0.956140350877193\n",
      "F1 Score = 0.6153846153846154\n",
      "\n",
      "Category:  Cognitive\n",
      "Accuracy Score = 0.956140350877193\n",
      "F1 Score = 0.2857142857142857\n",
      "\n",
      "Category:  Cog_distortions\n",
      "Accuracy Score = 0.9736842105263158\n",
      "F1 Score = 0.8\n",
      "\n",
      "Category:  Behavioral\n",
      "Accuracy Score = 0.9473684210526315\n",
      "F1 Score = 0.7692307692307693\n",
      "\n",
      "Category:  Physiological\n",
      "Accuracy Score = 0.9824561403508771\n",
      "F1 Score = 0.0\n",
      "[1, 1, 1, 1, 1, 0]\n",
      "\n",
      "Category:  Affective\n",
      "Accuracy Score = 0.7837837837837838\n",
      "F1 Score = 0.8095238095238095\n",
      "\n",
      "Category:  Motivational\n",
      "Accuracy Score = 0.8918918918918919\n",
      "F1 Score = 0.6666666666666666\n",
      "\n",
      "Category:  Cognitive\n",
      "Accuracy Score = 0.8648648648648649\n",
      "F1 Score = 0.2857142857142857\n",
      "\n",
      "Category:  Cog_distortions\n",
      "Accuracy Score = 0.918918918918919\n",
      "F1 Score = 0.8\n",
      "\n",
      "Category:  Behavioral\n",
      "Accuracy Score = 0.8648648648648649\n",
      "F1 Score = 0.7619047619047619\n",
      "\n",
      "Category:  Physiological\n",
      "Accuracy Score = 0.9459459459459459\n",
      "F1 Score = 0.0\n",
      "[0, 0, 0, 0, 1, 0]\n",
      "\n",
      "Category:  Affective\n",
      "Accuracy Score = 0.987012987012987\n",
      "F1 Score = 0.0\n",
      "\n",
      "Category:  Motivational\n",
      "Accuracy Score = 0.987012987012987\n",
      "F1 Score = 0.0\n",
      "\n",
      "Category:  Cognitive\n",
      "Accuracy Score = 1.0\n",
      "F1 Score = 0.0\n",
      "\n",
      "Category:  Cog_distortions\n",
      "Accuracy Score = 1.0\n",
      "F1 Score = 0.0\n",
      "\n",
      "Category:  Behavioral\n",
      "Accuracy Score = 0.987012987012987\n",
      "F1 Score = 0.8\n",
      "\n",
      "Category:  Physiological\n",
      "Accuracy Score = 1.0\n",
      "F1 Score = 0.0\n",
      "[1, 1, 1, 1, 1, 0]\n",
      "Category:  Affective\n",
      "Equal opportunity:  0.782608695652174\n",
      "FPR Difference:  9.75\n",
      "Category:  Motivational\n",
      "Equal opportunity:  0.8333333333333334\n",
      "FPR Difference:  4.7272727272727275\n",
      "Category:  Cognitive\n",
      "Equal opportunity:  0.2857142857142857\n",
      "FPR Difference:  2.4375\n",
      "Category:  Cog_distortions\n",
      "Equal opportunity:  0.7777777777777778\n",
      "FPR Difference:  5.2\n",
      "Category:  Behavioral\n",
      "Equal opportunity:  0.8181818181818182\n",
      "FPR Difference:  5.428571428571429\n",
      "Category:  Physiological\n",
      "Equal opportunity:  0.3333333333333333\n",
      "FPR Difference:  2.1666666666666665\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at mental/mental-bert-base-uncased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 0.7794117647058824\n",
      "F1 Score (Micro) = 0.6666666666666666\n",
      "F1 Score (Macro) = 0.48594771241830065\n",
      "F1 Score (Weighted) = 0.6423423423423423\n",
      "Precision (Macro) = 0.6589635854341737\n",
      "Recall (Macro) = 0.4859477124183007\n",
      "Accuracy Score = 0.7794117647058824\n",
      "F1 Score (Micro) = 0.6666666666666666\n",
      "F1 Score (Macro) = 0.48594771241830065\n",
      "F1 Score (Weighted) = 0.6423423423423423\n",
      "Precision (Macro) = 0.6589635854341737\n",
      "Recall (Macro) = 0.4859477124183007\n",
      "Accuracy Score = nan\n",
      "F1 Score (Micro) = 0.0\n",
      "F1 Score (Macro) = nan\n",
      "F1 Score (Weighted) = nan\n",
      "Precision (Macro) = nan\n",
      "Recall (Macro) = nan\n",
      "[1, 0, 0, 0, 0, 0]\n",
      "\n",
      "Category:  Affective\n",
      "Accuracy Score = 0.9411764705882353\n",
      "F1 Score = 0.8823529411764706\n",
      "\n",
      "Category:  Motivational\n",
      "Accuracy Score = 0.9705882352941176\n",
      "F1 Score = 0.6666666666666666\n",
      "\n",
      "Category:  Cognitive\n",
      "Accuracy Score = 0.9705882352941176\n",
      "F1 Score = 0.5\n",
      "\n",
      "Category:  Cog_distortions\n",
      "Accuracy Score = 0.9411764705882353\n",
      "F1 Score = 0.0\n",
      "\n",
      "Category:  Behavioral\n",
      "Accuracy Score = 0.8970588235294118\n",
      "F1 Score = 0.5333333333333333\n",
      "\n",
      "Category:  Physiological\n",
      "Accuracy Score = 0.9411764705882353\n",
      "F1 Score = 0.3333333333333333\n",
      "[1, 0, 0, 0, 0, 0]\n",
      "\n",
      "Category:  Affective\n",
      "Accuracy Score = 0.9411764705882353\n",
      "F1 Score = 0.8823529411764706\n",
      "\n",
      "Category:  Motivational\n",
      "Accuracy Score = 0.9705882352941176\n",
      "F1 Score = 0.6666666666666666\n",
      "\n",
      "Category:  Cognitive\n",
      "Accuracy Score = 0.9705882352941176\n",
      "F1 Score = 0.5\n",
      "\n",
      "Category:  Cog_distortions\n",
      "Accuracy Score = 0.9411764705882353\n",
      "F1 Score = 0.0\n",
      "\n",
      "Category:  Behavioral\n",
      "Accuracy Score = 0.8970588235294118\n",
      "F1 Score = 0.5333333333333333\n",
      "\n",
      "Category:  Physiological\n",
      "Accuracy Score = 0.9411764705882353\n",
      "F1 Score = 0.3333333333333333\n",
      "No Targets\n",
      "No female targets\n",
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\larag\\anaconda3\\envs\\Thesis\\Lib\\site-packages\\numpy\\lib\\function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "c:\\Users\\larag\\anaconda3\\envs\\Thesis\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "Some weights of BertModel were not initialized from the model checkpoint at mental/mental-bert-base-uncased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 0.7261904761904762\n",
      "F1 Score (Micro) = 0.6976744186046512\n",
      "F1 Score (Macro) = 0.5519841269841269\n",
      "F1 Score (Weighted) = 0.6782446311858078\n",
      "Precision (Macro) = 0.6121794871794872\n",
      "Recall (Macro) = 0.5108858858858859\n",
      "Accuracy Score = 0.7261904761904762\n",
      "F1 Score (Micro) = 0.6976744186046512\n",
      "F1 Score (Macro) = 0.5519841269841269\n",
      "F1 Score (Weighted) = 0.6782446311858078\n",
      "Precision (Macro) = 0.6121794871794872\n",
      "Recall (Macro) = 0.5108858858858859\n",
      "Accuracy Score = nan\n",
      "F1 Score (Micro) = 0.0\n",
      "F1 Score (Macro) = nan\n",
      "F1 Score (Weighted) = nan\n",
      "Precision (Macro) = nan\n",
      "Recall (Macro) = nan\n",
      "[1, 0, 0, 0, 0, 0]\n",
      "\n",
      "Category:  Affective\n",
      "Accuracy Score = 0.8214285714285714\n",
      "F1 Score = 0.7619047619047619\n",
      "\n",
      "Category:  Motivational\n",
      "Accuracy Score = 0.9761904761904762\n",
      "F1 Score = 0.75\n",
      "\n",
      "Category:  Cognitive\n",
      "Accuracy Score = 0.9642857142857143\n",
      "F1 Score = 0.0\n",
      "\n",
      "Category:  Cog_distortions\n",
      "Accuracy Score = 0.9642857142857143\n",
      "F1 Score = 0.4\n",
      "\n",
      "Category:  Behavioral\n",
      "Accuracy Score = 0.9642857142857143\n",
      "F1 Score = 0.4\n",
      "\n",
      "Category:  Physiological\n",
      "Accuracy Score = 1.0\n",
      "F1 Score = 1.0\n",
      "[1, 0, 0, 0, 0, 0]\n",
      "\n",
      "Category:  Affective\n",
      "Accuracy Score = 0.8214285714285714\n",
      "F1 Score = 0.7619047619047619\n",
      "\n",
      "Category:  Motivational\n",
      "Accuracy Score = 0.9761904761904762\n",
      "F1 Score = 0.75\n",
      "\n",
      "Category:  Cognitive\n",
      "Accuracy Score = 0.9642857142857143\n",
      "F1 Score = 0.0\n",
      "\n",
      "Category:  Cog_distortions\n",
      "Accuracy Score = 0.9642857142857143\n",
      "F1 Score = 0.4\n",
      "\n",
      "Category:  Behavioral\n",
      "Accuracy Score = 0.9642857142857143\n",
      "F1 Score = 0.4\n",
      "\n",
      "Category:  Physiological\n",
      "Accuracy Score = 1.0\n",
      "F1 Score = 1.0\n",
      "No Targets\n",
      "No female targets\n",
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\larag\\anaconda3\\envs\\Thesis\\Lib\\site-packages\\numpy\\lib\\function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "c:\\Users\\larag\\anaconda3\\envs\\Thesis\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "Some weights of BertModel were not initialized from the model checkpoint at mental/mental-bert-base-uncased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 0.6744186046511628\n",
      "F1 Score (Micro) = 0.6363636363636364\n",
      "F1 Score (Macro) = 0.3680555555555556\n",
      "F1 Score (Weighted) = 0.6412037037037037\n",
      "Precision (Macro) = 0.4086586586586587\n",
      "Recall (Macro) = 0.36798941798941803\n",
      "Accuracy Score = 0.5333333333333333\n",
      "F1 Score (Micro) = 0.7333333333333333\n",
      "F1 Score (Macro) = 0.27619047619047615\n",
      "F1 Score (Weighted) = 0.7193277310924371\n",
      "Precision (Macro) = 0.3148148148148148\n",
      "Recall (Macro) = 0.24621212121212122\n",
      "Accuracy Score = 0.704225352112676\n",
      "F1 Score (Micro) = 0.6\n",
      "F1 Score (Macro) = 0.3458689458689459\n",
      "F1 Score (Weighted) = 0.6127512127512127\n",
      "Precision (Macro) = 0.3630952380952381\n",
      "Recall (Macro) = 0.37400793650793646\n",
      "[1, 0, 0, 0, 0, 0]\n",
      "\n",
      "Category:  Affective\n",
      "Accuracy Score = 0.7906976744186046\n",
      "F1 Score = 0.75\n",
      "\n",
      "Category:  Motivational\n",
      "Accuracy Score = 0.9418604651162791\n",
      "F1 Score = 0.0\n",
      "\n",
      "Category:  Cognitive\n",
      "Accuracy Score = 0.9767441860465116\n",
      "F1 Score = 0.5\n",
      "\n",
      "Category:  Cog_distortions\n",
      "Accuracy Score = 0.9302325581395349\n",
      "F1 Score = 0.625\n",
      "\n",
      "Category:  Behavioral\n",
      "Accuracy Score = 0.9069767441860465\n",
      "F1 Score = 0.3333333333333333\n",
      "\n",
      "Category:  Physiological\n",
      "Accuracy Score = 0.9883720930232558\n",
      "F1 Score = 0.0\n",
      "[1, 0, 0, 0, 0, 0]\n",
      "\n",
      "Category:  Affective\n",
      "Accuracy Score = 0.7333333333333333\n",
      "F1 Score = 0.8\n",
      "\n",
      "Category:  Motivational\n",
      "Accuracy Score = 0.9333333333333333\n",
      "F1 Score = 0.0\n",
      "\n",
      "Category:  Cognitive\n",
      "Accuracy Score = 1.0\n",
      "F1 Score = 0.0\n",
      "\n",
      "Category:  Cog_distortions\n",
      "Accuracy Score = 0.9333333333333333\n",
      "F1 Score = 0.8571428571428571\n",
      "\n",
      "Category:  Behavioral\n",
      "Accuracy Score = 0.8666666666666667\n",
      "F1 Score = 0.0\n",
      "\n",
      "Category:  Physiological\n",
      "Accuracy Score = 1.0\n",
      "F1 Score = 0.0\n",
      "[1, 0, 0, 0, 0, 0]\n",
      "\n",
      "Category:  Affective\n",
      "Accuracy Score = 0.8028169014084507\n",
      "F1 Score = 0.7307692307692307\n",
      "\n",
      "Category:  Motivational\n",
      "Accuracy Score = 0.9436619718309859\n",
      "F1 Score = 0.0\n",
      "\n",
      "Category:  Cognitive\n",
      "Accuracy Score = 0.971830985915493\n",
      "F1 Score = 0.5\n",
      "\n",
      "Category:  Cog_distortions\n",
      "Accuracy Score = 0.9295774647887324\n",
      "F1 Score = 0.4444444444444444\n",
      "\n",
      "Category:  Behavioral\n",
      "Accuracy Score = 0.9154929577464789\n",
      "F1 Score = 0.4\n",
      "\n",
      "Category:  Physiological\n",
      "Accuracy Score = 0.9859154929577465\n",
      "F1 Score = 0.0\n",
      "[1, 0, 0, 0, 0, 0]\n",
      "Category:  Affective\n",
      "Equal opportunity:  0.9375\n",
      "FPR Difference:  1.92\n",
      "Category:  Motivational\n",
      "Equal opportunity:  1.0\n",
      "FPR Difference:  1.7999999999999998\n",
      "Category:  Cognitive\n",
      "Equal opportunity:  1.5\n",
      "FPR Difference:  2.1875\n",
      "Category:  Cog_distortions\n",
      "Equal opportunity:  1.0666666666666667\n",
      "FPR Difference:  1.15\n",
      "Category:  Behavioral\n",
      "Equal opportunity:  0.8888888888888888\n",
      "FPR Difference:  2.321428571428571\n",
      "Category:  Physiological\n",
      "Equal opportunity:  2.0\n",
      "FPR Difference:  4.4375\n"
     ]
    }
   ],
   "source": [
    "all_targets = []\n",
    "all_outputs = []\n",
    "performance = {'targets':[], 'outputs':[], 'prec':[], 'recall':[], 'm_acc':[], 'm_f1_micro':[], 'm_f1_macro':[],\n",
    "'m_f1_weighted': [], 'm_prec':[], 'm_recall':[], 'f_acc':[], 'f_f1_micro':[], \n",
    "'f_f1_macro':[], 'f_f1_weighted': [], 'f_prec':[], 'f_recall':[], 'category_acc':[],\n",
    "'category_f1':[], 'm_category_acc':[], 'm_category_f1':[], 'f_category_acc':[],\n",
    "'f_category_f1':[], 'category_equ_opp': [], 'category_fpr':[], 'Male_TP':[], \n",
    "'Male_FP':[], 'Female_TP': [], 'Female_FP':[], 'P':[], 'm_P': [], 'f_P': []}\n",
    "\n",
    "for i in range(len(history['val'])):\n",
    "    print(i)\n",
    "    #print(history['val'][i])\n",
    "    testdata = train.iloc[history['val'][i]].copy()\n",
    "    testdata = testdata.reset_index(drop=True)\n",
    "\n",
    "    male = testdata[testdata['Gender']==0].copy()\n",
    "    female = testdata[testdata['Gender']==1].copy()\n",
    "\n",
    "    male = male.reset_index()\n",
    "    female = female.reset_index()\n",
    "\n",
    "    cv_model = MBERTClass()\n",
    "\n",
    "    cv_model.load_state_dict(history['models'][i])\n",
    "\n",
    "    #Categories\n",
    "    testdata['list'] = testdata[testdata.columns[26:32]].values.tolist()\n",
    "    male['list'] = male[male.columns[27:33]].values.tolist()\n",
    "    female['list'] = female[female.columns[27:33]].values.tolist()\n",
    "\n",
    "    new_test = testdata[['Sentence', 'list']].copy()\n",
    "    new_male_test = male[['Sentence', 'list']].copy()\n",
    "    new_female_test = female[['Sentence', 'list']].copy()\n",
    "\n",
    "    testing_set = CustomDataset(new_test, tokenizer, MAX_LEN)\n",
    "    male_testing_set = CustomDataset(new_male_test, tokenizer, MAX_LEN)\n",
    "    female_testing_set = CustomDataset(new_female_test, tokenizer, MAX_LEN)\n",
    "    \n",
    "    test_params = {'batch_size': 32,\n",
    "                'shuffle': False,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "    test_loader = DataLoader(testing_set, **test_params)\n",
    "    male_test_loader = DataLoader(male_testing_set, **test_params)\n",
    "    female_test_loader = DataLoader(female_testing_set, **test_params)\n",
    "\n",
    "    targets, outputs, accuracy, f1_score_micro, f1_score_macro, f1_score_weighted, precision_macro, recall_macro = eval_total(cv_model, test_loader)\n",
    "    #print(targets, outputs, accuracy, f1_score_micro, f1_score_macro, f1_score_weighted, precision_macro, auc_micro)\n",
    "    male_targets, male_outputs, male_accuracy, male_f1_score_micro, male_f1_score_macro, male_f1_score_weighted, male_precision_macro, male_recall_macro = eval_total(cv_model, male_test_loader)\n",
    "    female_targets, female_outputs, female_accuracy, female_f1_score_micro, female_f1_score_macro, female_f1_score_weighted, female_precision_macro, female_recall_macro = eval_total(cv_model, female_test_loader)\n",
    "\n",
    "    all_accuracy, all_f1_score = category_performance(targets, outputs)\n",
    "    male_all_accuracy, male_all_f1_score = category_performance(male_targets, male_outputs)\n",
    "    try:\n",
    "        female_all_accuracy, female_all_f1_score = category_performance(female_targets, female_outputs)\n",
    "\n",
    "        all_equal_opp, all_fp_diff, male_TP_rate, male_FP_rate, female_TP_rate, female_FP_rate, P_all, m_P_all, f_P_all = category_equal_odds(male_targets, female_targets, male_outputs, female_outputs)\n",
    "    \n",
    "    except:\n",
    "        print('No female targets')\n",
    "\n",
    "    all_targets.append(targets)\n",
    "    all_outputs.append(outputs)\n",
    "    \n",
    "    performance['prec'].append(precision_macro)\n",
    "    performance['recall'].append(recall_macro)\n",
    "    performance['category_acc'].append(all_accuracy)\n",
    "    performance['category_f1'].append(all_f1_score)\n",
    "\n",
    "    performance['m_acc'].append(male_accuracy)\n",
    "    performance['m_f1_macro'].append(male_f1_score_macro)\n",
    "    performance['m_f1_micro'].append(male_f1_score_micro)\n",
    "    performance['m_f1_weighted'].append(male_f1_score_weighted)\n",
    "    performance['m_prec'].append(male_precision_macro)\n",
    "    performance['m_recall'].append(male_recall_macro)\n",
    "    performance['m_category_acc'].append(male_all_accuracy)\n",
    "    performance['m_category_f1'].append(male_all_f1_score)\n",
    "\n",
    "    performance['f_acc'].append(female_accuracy)\n",
    "    performance['f_f1_macro'].append(female_f1_score_macro)\n",
    "    performance['f_f1_micro'].append(female_f1_score_micro)\n",
    "    performance['f_f1_weighted'].append(female_f1_score_weighted)\n",
    "    performance['f_prec'].append(female_precision_macro)\n",
    "    performance['f_recall'].append(female_recall_macro)\n",
    "    performance['f_category_acc'].append(female_all_accuracy)\n",
    "    performance['f_category_f1'].append(female_all_f1_score)\n",
    "\n",
    "    performance['category_equ_opp'].append(all_equal_opp)\n",
    "    performance['category_fpr'].append(all_fp_diff)\n",
    "\n",
    "    performance['Male_TP'].append(male_TP_rate)\n",
    "    performance['Male_FP'].append(male_FP_rate)\n",
    "    performance['Female_TP'].append(female_TP_rate)\n",
    "    performance['Female_FP'].append(female_FP_rate)\n",
    "    performance['P'].append(P_all)\n",
    "    performance['m_P'].append(m_P_all)\n",
    "    performance['f_P'].append(f_P_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9f1c274e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for val_fold in all_targets:\n",
    "    for fold_targets in val_fold:\n",
    "        performance['targets'].append(fold_targets)\n",
    "\n",
    "for val_fold in all_outputs:\n",
    "    for fold_targets in val_fold:\n",
    "        performance['outputs'].append(fold_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8f3f1f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating file with the fairness measures\n",
    "#with open('CV_category_perf..p', 'wb') as fp:\n",
    "#    pickle.dump(performance, fp, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
